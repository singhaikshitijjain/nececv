Metadata-Version: 2.4
Name: nececv
Version: 0.2.3
Summary: NECECV – LLMs, Computer Vision, and Enterprise Semantic Cache
Home-page: https://github.com/singhaikshitijjain/nececv
Author: Singhai Kshitij Jain
Author-email: singhaikshitij143@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy
Requires-Dist: Pillow
Requires-Dist: tensorflow
Requires-Dist: opencv-python
Requires-Dist: matplotlib
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

NECECV

NECECV is an advanced AI systems platform that combines:

Generative Language Models

Computer Vision Intelligence

Enterprise-grade Semantic Caching Infrastructure

NECECV is designed to act as a foundation layer for building high-performance AI agents, copilots, and automation systems.

Features
1. Generative Universe Engine

A hierarchical generative language model inspired by planetary systems, enabling layered semantic reasoning and structured text generation.

nececv.planet_generative_model

2. Computer Vision – PreEdge

A hybrid deep-learning + epsilon-learning edge detection system built on top of VGG16, Canny, and Sobel filtering.

Supports:

Object classification

Edge density estimation

Adaptive edge detection

Visualization

nececv.obj_det.PreEdge

3. Enterprise Semantic Cache

A RAM-bounded, vector-aware cache layer for LLMs, APIs, and AI agents.

Supports:

Semantic similarity matching

LRU eviction

FTPL (learning-based eviction)

Real RAM budgeting

nececv.semantic_cache


This allows NECECV to behave like real AI infrastructure used in production systems.

Installation
pip install nececv

1️⃣ Generative Universe (LLM)
from nececv.planet_generative_model import llm_genUniverse

model = llm_genUniverse()
print(model.generate("AI will change the world"))

2️⃣ Computer Vision (PreEdge)
from nececv import PreEdge

detector = PreEdge()

predictions = detector.detect_object_probability("image.jpg")
edges = detector.generate_edge_image("image.jpg", predictions, epsilon=0.1, iterations=10)

detector.display_results("image.jpg", predictions=predictions, edge_image="Canny")

3️⃣ Semantic Cache (LLM Infra)
import nececv

cache = nececv.LRUSemanticCache(max_ram_mb=512)

def llm(query):
    return "LLM response for: " + query

router = nececv.SemanticRouter(cache, llm)

embedding = embed("reset password")   # user-provided embedding
router.query("reset password", embedding)


The cache automatically:

Finds semantic matches

Reuses previous outputs

Evicts data when RAM limit is reached
